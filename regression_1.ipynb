{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f37b20d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns  \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c425dbd6",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a3fddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TIME  FOOD  RAPI  LAI  BG\n",
      "0  00:00   NaN   NaN  NaN NaN\n",
      "1  00:10   NaN   NaN  NaN NaN\n",
      "2  00:20   NaN   NaN  NaN NaN\n",
      "3  00:30   NaN   NaN  NaN NaN\n",
      "4  00:40   NaN   NaN  NaN NaN\n"
     ]
    }
   ],
   "source": [
    "# reading the input file\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\vvsat\\\\Documents\\\\machine learning\\\\blood glucose challenge\\\\dataset_0.csv\")\n",
    "print(df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee86de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the 'TIME' column\n",
    "df = df.drop(\"TIME\", axis=1)\n",
    "#df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf094252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the head of the final dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f4729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the data\n",
    "print(\"VISUALISING THE INDEPENDENT RELATIONSHIPS\")\n",
    " \n",
    "sns.lmplot(x='FOOD', y='BG', data=df)\n",
    "\n",
    "sns.lmplot(x='RAPI', y='BG', data=df)  \n",
    "\n",
    "sns.lmplot(x='LAI', y='BG', data=df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c377d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the correlation between the given features\n",
    "corr = df.corr()\n",
    "print(corr)\n",
    "sns.heatmap(corr, \n",
    "         xticklabels=corr.columns, \n",
    "         yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6157a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding the skewness and kurtosis of the data\n",
    "\n",
    "print(\"AFTER LOG TRANSFORM) \\n \")\n",
    "print(\"SKEWNESS : \\n\",df.skew(axis = 0, skipna = True))\n",
    "print(\"\\n \\n KURTOSIS : \\n\",df.kurtosis(axis = 0, skipna = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc5f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying logrithmic transform for BG\n",
    "# applied only to the targets\n",
    "\n",
    "df['BG'] = np.log(df['BG']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef366648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# food, rapi and lai - independent variables\n",
    "x_df = df[['FOOD', 'RAPI', 'LAI']]\n",
    "\n",
    "# BG - dependent/predictor variable\n",
    "y_df = df['BG'] \n",
    "  \n",
    "x_df = x_df.to_numpy()\n",
    "y_df = y_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b415fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# imputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\", add_indicator=True)\n",
    "imputer.fit(x_df)\n",
    "\n",
    "x = imputer.transform(x_df)\n",
    "y = y_df.reshape(-1, 1)\n",
    "imputer.fit(y)\n",
    "y = imputer.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c6d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "\n",
    "# scaling the data with a mean value 0 and standard deviation of 1\n",
    "x = scaler.transform(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into train and test(20%) sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced85a5b",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b710878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create Linear Regression object\n",
    "model_lrg = linear_model.LinearRegression(fit_intercept=True, normalize='deprecated')\n",
    "\n",
    "model_lrg.fit(X_train, y_train) #fitting the model \n",
    "\n",
    "print('R^2 value =', model_lrg.score(X_train, y_train))  #Printing the R^2 value     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ff8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model \n",
    "prediction_test = model_lrg.predict(X_test)    \n",
    "print(y_test)\n",
    "print(prediction_test)\n",
    "print(\"Mean square error =\", np.mean(prediction_test-y_test)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('regression coefficient =', model_lrg.coef_, '\\n','regression intercept =', model_lrg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38199e8b",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de8680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9799b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the lasso model\n",
    "lasso = Lasso(random_state=None,  fit_intercept=True, normalize='deprecated', max_iter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e6a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "alphas = np.logspace(-4, -0.5, 30) # intercept\n",
    "\n",
    "# tuning alpha\n",
    "tuned_parameters = [{\"alpha\": alphas}]\n",
    "n_folds = 3\n",
    "\n",
    "model_lasso = GridSearchCV(lasso, tuned_parameters, cv=n_folds, refit=True)\n",
    "\n",
    "# refitting the lasso model with the tuned parameters\n",
    "model_lasso  = model_lasso.fit(X_train, y_train)\n",
    "\n",
    "print('R^2 value =', model_lasso.score(X_train, y_train))  #Printing the R^2 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0044aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the mean and standard deviation of the samples\n",
    "scores = model_lasso.cv_results_[\"mean_test_score\"]\n",
    "scores_std = model_lasso.cv_results_[\"std_test_score\"]\n",
    "plt.figure().set_size_inches(8, 6)\n",
    "plt.semilogx(alphas, scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634354b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot error lines showing +/- std. errors of the scores\n",
    "std_error = scores_std / np.sqrt(n_folds)\n",
    "\n",
    "plt.semilogx(alphas, scores + std_error, \"b--\")\n",
    "plt.semilogx(alphas, scores - std_error, \"b--\")\n",
    "\n",
    "# alpha=0.2 controls the translucency of the fill color\n",
    "plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
    "\n",
    "plt.ylabel(\"CV score +/- std error\")\n",
    "plt.xlabel(\"alpha\")\n",
    "\n",
    "# printing the maximum of the scores calculated\n",
    "plt.axhline(np.max(scores), linestyle=\"--\", color=\".3\")\n",
    "plt.xlim([alphas[0], alphas[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model \n",
    "prediction_test = model_lasso.predict(X_test)    \n",
    "\n",
    "print(y_test, prediction_test)\n",
    "print(\"Mean square error =\", np.mean(prediction_test-y_test)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7c459c",
   "metadata": {},
   "source": [
    "# RIDGE LINEAR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f613bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4ab6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the lasso model\n",
    "ridge = Ridge(random_state=None,  fit_intercept=True, normalize='deprecated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730dbbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "alphas = np.logspace(-4, -0.5, 30) # intercept\n",
    "\n",
    "# tuning alpha\n",
    "tuned_parameters = [{\"alpha\": alphas}]\n",
    "n_folds = 3\n",
    "\n",
    "model_ridge = GridSearchCV(ridge, tuned_parameters, cv=n_folds, refit=True)\n",
    "\n",
    "# refitting the lasso model with the tuned parameters\n",
    "model_ridge  = model_ridge.fit(X_train, y_train)\n",
    "\n",
    "print('R^2 value =', model_ridge.score(X_train, y_train))  #Printing the R^2 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3942109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the mean and standard deviation of the samples\n",
    "scores = model_ridge.cv_results_[\"mean_test_score\"]\n",
    "scores_std = model_ridge.cv_results_[\"std_test_score\"]\n",
    "plt.figure().set_size_inches(8, 6)\n",
    "plt.semilogx(alphas, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02822314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot error lines showing +/- std. errors of the scores\n",
    "std_error = scores_std / np.sqrt(n_folds)\n",
    "\n",
    "plt.semilogx(alphas, scores + std_error, \"b--\")\n",
    "plt.semilogx(alphas, scores - std_error, \"b--\")\n",
    "\n",
    "# alpha=0.2 controls the translucency of the fill color\n",
    "plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
    "\n",
    "plt.ylabel(\"CV score +/- std error\")\n",
    "plt.xlabel(\"alpha\")\n",
    "\n",
    "# printing the maximum of the scores calculated\n",
    "plt.axhline(np.max(scores), linestyle=\"--\", color=\".3\")\n",
    "plt.xlim([alphas[0], alphas[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4612ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model \n",
    "prediction_test = model_ridge.predict(X_test)    \n",
    "\n",
    "print(y_test, prediction_test)\n",
    "print(\"Mean square error =\", np.mean(prediction_test-y_test)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5671cdd4",
   "metadata": {},
   "source": [
    "# POLYNOMIAL REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e68da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial features\n",
    "for degree in [2, 3, 4]:\n",
    "    model_pf = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=1e-3))\n",
    "    model_pf.fit(X_train, y_train)\n",
    "    \n",
    "    print('R^2 value for degree', degree, '=', model_pf.score(X_train, y_train))  #Printing the R^2 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb2887",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 4\n",
    "model_pf = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=1e-3))\n",
    "model_pf.fit(X_train, y_train)      \n",
    "\n",
    "print('R^2 value for degree',degree,'=', model_pf.score(X_train, y_train))  #Printing the R^2 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc75ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model \n",
    "prediction_test = model_pf.predict(X_test)    \n",
    "print(y_test)\n",
    "print(prediction_test)\n",
    "print(\"Mean square error =\", np.mean(prediction_test-y_test)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd278ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "estimator_1 = [\n",
    "    (\"linear regression\", model_lrg), \n",
    "    (\"Polynomial Regression\", model_pf)\n",
    "]\n",
    "\n",
    "stacking_regressor_1 = StackingRegressor(estimators=estimator_1)\n",
    "stacking_regressor_1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b4f488",
   "metadata": {},
   "source": [
    "# VISUALISING THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb3c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "\n",
    "\n",
    "def plot_regression_results(ax, y_true, y_pred, title, scores, elapsed_time):\n",
    "    \"\"\"Scatter plot of the predicted vs true targets.\"\"\"\n",
    "    ax.plot(\n",
    "        [y_true.min(), y_true.max()], [y_true.min(), y_true.max()], \"--r\", linewidth=2\n",
    "    )\n",
    "    ax.scatter(y_true, y_pred, alpha=0.2)\n",
    "\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.spines[\"left\"].set_position((\"outward\", 10))\n",
    "    ax.spines[\"bottom\"].set_position((\"outward\", 10))\n",
    "    ax.set_xlim([y_true.min(), y_true.max()])\n",
    "    ax.set_ylim([y_true.min(), y_true.max()])\n",
    "    ax.set_xlabel(\"Measured\")\n",
    "    ax.set_ylabel(\"Predicted\")\n",
    "    extra = plt.Rectangle(\n",
    "        (0, 0), 0, 0, fc=\"w\", fill=False, edgecolor=\"none\", linewidth=0\n",
    "    )\n",
    "    ax.legend([extra], [scores], loc=\"upper left\")\n",
    "    title = title + \"\\n Evaluation in {:.2f} seconds\".format(elapsed_time)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a0b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(9, 7))\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "for ax, (name, est) in zip(\n",
    "    axs, estimator_1 + [(\"Stacking Regressor\", stacking_regressor_1)]\n",
    "):\n",
    "    start_time = time.time()\n",
    "    score = cross_validate(\n",
    "        est, X_test, y_test, scoring=[\"r2\", \"neg_mean_absolute_error\"], n_jobs=2, verbose=0\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    y_pred = cross_val_predict(est, X_test, y_test, n_jobs=2, verbose=0)\n",
    "\n",
    "    plot_regression_results(\n",
    "        ax,\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        name,\n",
    "        (r\"$R^2={:.2f} \\pm {:.2f}$\" + \"\\n\" + r\"$MAE={:.2f} \\pm {:.2f}$\").format(\n",
    "            np.mean(score[\"test_r2\"]),\n",
    "            np.std(score[\"test_r2\"]),\n",
    "            -np.mean(score[\"test_neg_mean_absolute_error\"]),\n",
    "            np.std(score[\"test_neg_mean_absolute_error\"]),\n",
    "        ),\n",
    "        elapsed_time,\n",
    "    )\n",
    "    \n",
    "plt.suptitle(\"Single predictors versus stacked predictors \\n\")\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd777f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
